First, a lexer turns the linear sequence of characters into a linear sequence of tokens; this is known as "[lexical analysis](https://en.wikipedia.org/wiki/Lexical_analysis "Lexical analysis")" or "lexing". Second, the parser turns the linear sequence of tokens into a hierarchical syntax tree; this is known as "[parsing](https://en.wikipedia.org/wiki/Parsing "Parsing")" narrowly speaking. Thirdly, the contextual analysis resolves names and checks types. This modularity is sometimes possible, but in many real-world languages an earlier step depends on a later step – for example, [the lexer hack](https://en.wikipedia.org/wiki/The_lexer_hack "The lexer hack") in C is because tokenization depends on context. Even in these cases, syntactical analysis is often seen as approximating this ideal model.

In some languages like Perl and Lisp the **specification (or implementation) of the language allows constructs that execute during the parsing phase**. **Furthermore, these languages have constructs that allow the programmer to alter the behavior of the parser.** **This combination effectively blurs the distinction between parsing and execution, and makes syntax analysis an [undecidable problem](https://en.wikipedia.org/wiki/Undecidable_problem "Undecidable problem") in these languages, meaning that the parsing phase may not finish


### From Parser to Scanner
The solution generally consists of feeding information from the semantic [symbol table](https://en.wikipedia.org/wiki/Symbol_table "Symbol table") back into the lexer. That is, rather than functioning as a pure one-way [pipeline](https://en.wikipedia.org/wiki/Pipeline_(software) "Pipeline (software)") from the lexer to the parser, there is a backchannel from semantic analysis back to the lexer. This mixing of parsing and semantic analysis is generally regarded as inelegant, which is why it is called a "[hack](https://en.wikipedia.org/wiki/Hack_(computer_science) "Hack (computer science)")".

Without added context, the lexer cannot distinguish type identifiers from other identifiers because all identifiers have the same format. With the hack in the above example, when the lexer finds the identifier _A_ it should be able to classify the token as a type identifier. The rules of the language would be clarified by specifying that typecasts require a type identifier and the ambiguity disappears.