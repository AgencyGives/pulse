Each **Agent** is a **Higher-Order Virtual Machine** with a local **Belief Base** a **Function Factory** and store of **Functions**.
<mark style="background: #ADCCFFA6;">NOTE: EMIT IS NOT THE SAME AS RETURN FOR FUNCTIONS</mark>
Functions and Agents "speak" Propositions. They emit messages and listen for them to route them through a network.

These Propositions can be *possible*, *impossible*, *necessary*, *contingent* or any other logic.

**Agents** can **Believe** Propositions or **Accept** them in a context.

**Beliefs** are stored in the **Belief Base**.

**Functions** take in **Propositions** as input variables and return new **Propositions**

// The negation of input preconditions is a useful **"Propositional Accounting"** procedure, new propositions can show transformation of the world.

**Agents** can **Believe** **Propositions** B( φ) *about what ψ is inputted in a **Function's input variable** and thus reason as to whether ψ is possible*, *impossible*, *necessary*, *contingent* or any other logic...

**Agents** reason over their **Belief Base** to determine what **Propositions to emit**, to determine what Beliefs it will hold.

**Agents and Functions** can emit: **p | ¬ϕ | ϕ ∧ ϕ | Biϕ | EBGϕ | CBGϕ | Ac iϕ | EAcϕ | CAcϕ**

Emitted **Proposition's type** is the **hash** of the **Function** that emitted.
*// Agents are just an interface of functions, agents are a function, its all functions all the way down and up, in all directions*

This **hash** permits an **Agent** or **Function** to lookup the **Function** that created a **Proposition** simply by seeing the Proposition's **type**.

**Hashes** even *hashes of a* **Function** can have multiple corresponding **Functions** so the ***Agent Believes that a Hash corresponds to a certain Function**. 
// This is effectively a **PDHT: Propositional Distributed Hash Table** (ot Play-DHT), whose mapping is based on Belief. Mapping can be  *possible*, *impossible*, *necessary*, *contingent* or any other logic... *Hash collisions can be reasoned over and be the  product of reason.*

This also effictively **turns hashes into variables for which propositions can be inputed or function outputs can be inputed** allowing for the *possible*, *impossible*, *necessary*, *contingent*, configuration, or any other logic of how/if/when under what conditions functions should pass into one another, or *what Propositions are the input variables of a Function* and what Functions are being reffered to in the hash of a Proposition's Type.

**Welcome to Expressable Configurable and Distributed Dynamicly Programmable Higher Order Function Network.**

**Propositions**, **Functions** and **Agents** (**Instances**) have Hashes in a **PDHT** so all can be dymically configurable. **Access** of Agents to a function can be functionally programmed...

An Agent's changing Beliefs can thus change their Beliefs about the structure of how functions pass into eachother, the Agent may find that it's access to a Function has dissapeared. Access to a function is what rendered an interface meaningful, thus the programmable remapping of the PDHT is also a means of creating dynamic and **programmable interfaces.**

## Routing
Every Agent maintains a **Routing Log**.

When an Agent Believes a Proposition returned by a Function it records the *hash* of the Propositions inputted into the Function to yield a particular Proposition in its **Routing Log**. 

Each entry in the **Routing Log** is then a snapshot of a moment in which agent(s) believe a proposition as actual and everything about it's creation to be possible. This momentary point of view is captured in the routing log. *Strings weave through Evental Encounters...*

**This routing log is also a Routing Table...** 
**// PDRT Propositional Distributed Routing Table for Networking Communication** -> Agents can also tell neighbors how to network a message from them, based on how they Believe a Network is organized.

## **Meaning**
Every Proposition references the Agent/Function that returned it. When an Agent comes across a Proposition and wants to know what it "means" a good place to look is what Function returned that Proposition, what other Propositions were passed into that Functions Variables

And because every Proposition returned by a function has a routing log entry: **An Agent can find Routing Log's recursively and reason as to whether they "really mean the same thing".**

> It's only stored in the routing log, if the Agent Belived it.

**This allows an Agent to find an Agent's Routing Log and reason as to whether they are "really mean the same thing".**

if I wish to find the Input Variables a Believer of Proposition considered 

Propositions are routed forwards and backwards through the local common ground perception of routing tables.

Backwards propogation of Propositions, forwards propogation of plausability, and storage  by agent that Believed the claim.

If the agent's Belief was made with the expectation of future access, those giving access (mega-party) could base it not just on your belief but on network-plausability, and the difference between network plausability and your claim.

You may say "I did 500 pies" it routes backwards and their is a maximum claim possible.

the spread between max poss and claim can limit access... aka dont lie too much about what u did or i wont give u access.